<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>老东叔写代码</title>
<meta name=keywords content><meta name=description content="Redis复习 +++
title = &#34;&#34; date = 2024-03-20T19:11:14+08:00 lastmod = 2024-03-20T19:11:14+08:00 author = [&ldquo;jiandong.liu93&rdquo;] draft = true +++
IO模型 数据结构 写数据 1. rehash
哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。
所以，Redis 会对哈希表做 rehash 操作，也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。
在传统的Rehash中，当哈希表需要扩容时，Redis会一次性地将所有键重新计算哈希值，并重新分配到新的哈希表中。这种方式可能会导致在数据量巨大时的性能问题。为了解决这个问题，Redis引入了渐进式Rehash技术，其原理如下
（1）为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。
（2）在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。
（3）在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。"><meta name=author content="jiandong.liu93"><link rel=canonical href=https://meepoljd.github.io/posts/redis-moc/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://meepoljd.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://meepoljd.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://meepoljd.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://meepoljd.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://meepoljd.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content><meta property="og:description" content="Redis复习 +++
title = &#34;&#34; date = 2024-03-20T19:11:14+08:00 lastmod = 2024-03-20T19:11:14+08:00 author = [&ldquo;jiandong.liu93&rdquo;] draft = true +++
IO模型 数据结构 写数据 1. rehash
哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。
所以，Redis 会对哈希表做 rehash 操作，也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。
在传统的Rehash中，当哈希表需要扩容时，Redis会一次性地将所有键重新计算哈希值，并重新分配到新的哈希表中。这种方式可能会导致在数据量巨大时的性能问题。为了解决这个问题，Redis引入了渐进式Rehash技术，其原理如下
（1）为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。
（2）在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。
（3）在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。"><meta property="og:type" content="article"><meta property="og:url" content="https://meepoljd.github.io/posts/redis-moc/"><meta property="og:image" content="https://meepoljd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="og:site_name" content="老东叔写代码"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://meepoljd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content><meta name=twitter:description content="Redis复习 +++
title = &#34;&#34; date = 2024-03-20T19:11:14+08:00 lastmod = 2024-03-20T19:11:14+08:00 author = [&ldquo;jiandong.liu93&rdquo;] draft = true +++
IO模型 数据结构 写数据 1. rehash
哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。
所以，Redis 会对哈希表做 rehash 操作，也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。
在传统的Rehash中，当哈希表需要扩容时，Redis会一次性地将所有键重新计算哈希值，并重新分配到新的哈希表中。这种方式可能会导致在数据量巨大时的性能问题。为了解决这个问题，Redis引入了渐进式Rehash技术，其原理如下
（1）为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。
（2）在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。
（3）在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://meepoljd.github.io/posts/"},{"@type":"ListItem","position":2,"name":"","item":"https://meepoljd.github.io/posts/redis-moc/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"Redis复习 +++\ntitle = \u0026quot;\u0026quot; date = 2024-03-20T19:11:14+08:00 lastmod = 2024-03-20T19:11:14+08:00 author = [\u0026ldquo;jiandong.liu93\u0026rdquo;] draft = true +++\nIO模型 数据结构 写数据 1. rehash\n哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。\n所以，Redis 会对哈希表做 rehash 操作，也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。\n在传统的Rehash中，当哈希表需要扩容时，Redis会一次性地将所有键重新计算哈希值，并重新分配到新的哈希表中。这种方式可能会导致在数据量巨大时的性能问题。为了解决这个问题，Redis引入了渐进式Rehash技术，其原理如下\n（1）为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。\n（2）在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。\n（3）在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。","keywords":[],"articleBody":"Redis复习 +++\ntitle = \"\" date = 2024-03-20T19:11:14+08:00 lastmod = 2024-03-20T19:11:14+08:00 author = [“jiandong.liu93”] draft = true +++\nIO模型 数据结构 写数据 1. rehash\n哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。\n所以，Redis 会对哈希表做 rehash 操作，也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。\n在传统的Rehash中，当哈希表需要扩容时，Redis会一次性地将所有键重新计算哈希值，并重新分配到新的哈希表中。这种方式可能会导致在数据量巨大时的性能问题。为了解决这个问题，Redis引入了渐进式Rehash技术，其原理如下\n（1）为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。\n（2）在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。\n（3）在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。\n（4）随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1，表示 rehash 操作已完成。\n渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。\n读数据 删除数据 「内存淘汰策略」和「过期删除策略」，\n过期 逐出 Redis 实现的是一种近似 LRU 算法，目的是为了更好的节约内存，它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。\n当 Redis 进行内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。\n持久化 RDB \u0026 AOF 水平扩展 集群架构\n主从同步\n主从故障转移操作包含以下四个步骤：\n第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」； 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端； 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点； 扩容\n在 Redis Cluster 中，数据被分成 16384 个哈希槽，每个节点负责一部分哈希槽。当需要迁移哈希槽时（例如，当增加或删除节点），Redis 提供了一种机制来处理这种情况。\n在哈希槽迁移的过程中，旧节点和新节点都会有关于这个哈希槽的信息。旧节点知道它正在将这个哈希槽迁移到新节点，新节点知道它正在从旧节点接收这个哈希槽。\n对于在迁移过程中对这个哈希槽的读操作，旧节点会正常处理。对于写操作，旧节点会处理并同时将数据发送给新节点，这样可以保证新节点和旧节点的数据一致。\n当哈希槽迁移完成后，新节点会成为这个哈希槽的负责节点，所有对这个哈希槽的读写操作都会直接由新节点处理。\n需要注意的是，这个过程可能会导致一些短暂的不一致，因为在哈希槽迁移完成前后，客户端可能会收到旧节点和新节点的不同的重定向信息。但是，Redis Cluster 提供了一种机制来处理这种情况，当客户端收到重定向信息时，它会更新自己的哈希槽到节点的映射信息，然后重试操作。\n总的来说，Redis Cluster 在哈希槽迁移的过程中，通过在旧节点和新节点之间复制数据，并在客户端重定向操作，来保证数据的可用性和一致性。\nHash与Rehash\n偏移问题 大key\n热Key\n灾备 主从切换\n哨兵机制\n主客观掉线\n投票\n选主\n客户端订阅\n客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。主从切换完成后，哨兵就会向 +switch-master 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了。\n通过发布者/订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。\n其他 这玩意不能回滚！！！\n第一步是，客户端获取当前时间（t1）。 第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作： 加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。 如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。 第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 \u003c 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。 大key的持久化影响\n当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。\nAOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 fork() 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：\n创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长； 创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。 大 key 除了会影响持久化之外，还会有以下的影响。\n客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。\n引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。\n阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。\n内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。\n如何避免大 Key 呢？\n最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。\n完！\n","wordCount":"256","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"jiandong.liu93"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://meepoljd.github.io/posts/redis-moc/"},"publisher":{"@type":"Organization","name":"老东叔写代码","logo":{"@type":"ImageObject","url":"https://meepoljd.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://meepoljd.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://meepoljd.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://meepoljd.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://meepoljd.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://meepoljd.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://meepoljd.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent"></h1><div class=post-meta>2 min&nbsp;·&nbsp;256 words&nbsp;·&nbsp;jiandong.liu93</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#io模型>IO模型</a></li><li><a href=#数据结构>数据结构</a></li><li><a href=#写数据>写数据</a></li><li><a href=#读数据>读数据</a></li><li><a href=#删除数据>删除数据</a><ul><li><a href=#过期>过期</a></li><li><a href=#逐出>逐出</a></li></ul></li><li><a href=#持久化>持久化</a></li><li><a href=#水平扩展>水平扩展</a></li><li><a href=#偏移问题>偏移问题</a></li><li><a href=#灾备>灾备</a></li><li><a href=#其他>其他</a></li></ul></nav></div></details></div><div class=post-content><h1 id=redis复习>Redis复习<a hidden class=anchor aria-hidden=true href=#redis复习>#</a></h1><p>+++</p><p>title = ""
date = 2024-03-20T19:11:14+08:00
lastmod = 2024-03-20T19:11:14+08:00
author = [&ldquo;jiandong.liu93&rdquo;]
draft = true
+++</p><h2 id=io模型>IO模型<a hidden class=anchor aria-hidden=true href=#io模型>#</a></h2><h2 id=数据结构>数据结构<a hidden class=anchor aria-hidden=true href=#数据结构>#</a></h2><h2 id=写数据>写数据<a hidden class=anchor aria-hidden=true href=#写数据>#</a></h2><p>   1. rehash</p><p>哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。</p><p>　　所以，Redis 会对哈希表做 rehash 操作，也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。</p><p>在传统的Rehash中，当哈希表需要扩容时，Redis会一次性地将所有键重新计算哈希值，并重新分配到新的哈希表中。这种方式可能会导致在数据量巨大时的性能问题。为了解决这个问题，Redis引入了渐进式Rehash技术，其原理如下</p><p>（1）为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。</p><p>（2）在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。</p><p>（3）在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。</p><p>（4）随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1，表示 rehash 操作已完成。</p><p>渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。</p><h2 id=读数据>读数据<a hidden class=anchor aria-hidden=true href=#读数据>#</a></h2><h2 id=删除数据>删除数据<a hidden class=anchor aria-hidden=true href=#删除数据>#</a></h2><p>「内存淘汰策略」和「过期删除策略」，</p><h3 id=过期>过期<a hidden class=anchor aria-hidden=true href=#过期>#</a></h3><h3 id=逐出>逐出<a hidden class=anchor aria-hidden=true href=#逐出>#</a></h3><p>Redis 实现的是一种<strong>近似 LRU 算法</strong>，目的是为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。</p><p>当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，它是随机取 5 个值（此值可配置），然后<strong>淘汰最久没有使用的那个</strong>。</p><h2 id=持久化>持久化<a hidden class=anchor aria-hidden=true href=#持久化>#</a></h2><ol><li>RDB & AOF</li></ol><h2 id=水平扩展>水平扩展<a hidden class=anchor aria-hidden=true href=#水平扩展>#</a></h2><ol><li><p>集群架构</p></li><li><p>主从同步</p><ol><li><p>主从故障转移操作包含以下四个步骤：</p><ul><li>第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。</li><li>第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；</li><li>第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；</li><li>第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；</li></ul></li></ol></li><li><p>扩容</p><ol><li><p>在 Redis Cluster 中，数据被分成 16384 个哈希槽，每个节点负责一部分哈希槽。当需要迁移哈希槽时（例如，当增加或删除节点），Redis 提供了一种机制来处理这种情况。</p><p>在哈希槽迁移的过程中，旧节点和新节点都会有关于这个哈希槽的信息。旧节点知道它正在将这个哈希槽迁移到新节点，新节点知道它正在从旧节点接收这个哈希槽。</p><p>对于在迁移过程中对这个哈希槽的读操作，旧节点会正常处理。对于写操作，旧节点会处理并同时将数据发送给新节点，这样可以保证新节点和旧节点的数据一致。</p><p>当哈希槽迁移完成后，新节点会成为这个哈希槽的负责节点，所有对这个哈希槽的读写操作都会直接由新节点处理。</p><p>需要注意的是，这个过程可能会导致一些短暂的不一致，因为在哈希槽迁移完成前后，客户端可能会收到旧节点和新节点的不同的重定向信息。但是，Redis Cluster 提供了一种机制来处理这种情况，当客户端收到重定向信息时，它会更新自己的哈希槽到节点的映射信息，然后重试操作。</p><p>总的来说，Redis Cluster 在哈希槽迁移的过程中，通过在旧节点和新节点之间复制数据，并在客户端重定向操作，来保证数据的可用性和一致性。</p></li></ol></li><li><p>Hash与Rehash</p></li></ol><h2 id=偏移问题>偏移问题<a hidden class=anchor aria-hidden=true href=#偏移问题>#</a></h2><ol><li><p>大key</p></li><li><p>热Key</p></li></ol><h2 id=灾备>灾备<a hidden class=anchor aria-hidden=true href=#灾备>#</a></h2><ol><li><p>主从切换</p></li><li><p>哨兵机制</p><ol><li><p>主客观掉线</p></li><li><p>投票</p></li><li><p>选主</p></li><li><p>客户端订阅</p><ol><li><p>客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。<strong>主从切换完成后，哨兵就会向 <code>+switch-master</code> 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了</strong>。</p><p>通过发布者/订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。</p></li></ol><h2 id=其他>其他<a hidden class=anchor aria-hidden=true href=#其他>#</a></h2><ol><li><p>这玩意不能回滚！！！</p></li><li><ul><li>第一步是，客户端获取当前时间（t1）。</li><li>第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作：<ul><li>加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。</li><li>如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。</li></ul></li><li>第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。</li></ul></li><li><p>大key的持久化影响</p><p>当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。</p><p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：</p><ul><li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。</li></ul><p>大 key 除了会影响持久化之外，还会有以下的影响。</p><ul><li><p>客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</p></li><li><p>引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</p></li><li><p>阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</p></li><li><p>内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</p></li></ul><p>如何避免大 Key 呢？</p><p>最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。</p><p>完！</p></li></ol></li></ol></li></ol></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://meepoljd.github.io/posts/how-to-build-personal-website/><span class=title>« Prev</span><br><span>使用Hugo快速搭建一个免费的静态博客</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://meepoljd.github.io/>老东叔写代码</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>