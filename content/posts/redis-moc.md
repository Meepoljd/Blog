# Redis复习

+++

title = ""
date = 2024-03-20T19:11:14+08:00
lastmod = 2024-03-20T19:11:14+08:00
author = ["jiandong.liu93"]
draft = true
+++

## IO模型

## 数据结构

## 写数据

   1. rehash

哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说，这是不太能接受的。

　　所以，Redis 会对哈希表做 rehash 操作，也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。

在传统的Rehash中，当哈希表需要扩容时，Redis会一次性地将所有键重新计算哈希值，并重新分配到新的哈希表中。这种方式可能会导致在数据量巨大时的性能问题。为了解决这个问题，Redis引入了渐进式Rehash技术，其原理如下

（1）为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。

（2）在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。

（3）在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。

（4）随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1，表示 rehash 操作已完成。

渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。

## 读数据

## 删除数据

「内存淘汰策略」和「过期删除策略」，

### 过期

### 逐出

Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。

当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

## 持久化

1. RDB & AOF

## 水平扩展

1. 集群架构

2. 主从同步
   
   1. 主从故障转移操作包含以下四个步骤：
      
      - 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。
      - 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
      - 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
      - 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

3. 扩容
   
   1. 在 Redis Cluster 中，数据被分成 16384 个哈希槽，每个节点负责一部分哈希槽。当需要迁移哈希槽时（例如，当增加或删除节点），Redis 提供了一种机制来处理这种情况。
      
      在哈希槽迁移的过程中，旧节点和新节点都会有关于这个哈希槽的信息。旧节点知道它正在将这个哈希槽迁移到新节点，新节点知道它正在从旧节点接收这个哈希槽。
      
      对于在迁移过程中对这个哈希槽的读操作，旧节点会正常处理。对于写操作，旧节点会处理并同时将数据发送给新节点，这样可以保证新节点和旧节点的数据一致。
      
      当哈希槽迁移完成后，新节点会成为这个哈希槽的负责节点，所有对这个哈希槽的读写操作都会直接由新节点处理。
      
      需要注意的是，这个过程可能会导致一些短暂的不一致，因为在哈希槽迁移完成前后，客户端可能会收到旧节点和新节点的不同的重定向信息。但是，Redis Cluster 提供了一种机制来处理这种情况，当客户端收到重定向信息时，它会更新自己的哈希槽到节点的映射信息，然后重试操作。
      
      总的来说，Redis Cluster 在哈希槽迁移的过程中，通过在旧节点和新节点之间复制数据，并在客户端重定向操作，来保证数据的可用性和一致性。

4. Hash与Rehash

## 偏移问题

1. 大key

2. 热Key

## 灾备

1. 主从切换

2. 哨兵机制
   
   1. 主客观掉线
   
   2. 投票
   
   3. 选主
   
   4. 客户端订阅
      
      1. 客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。**主从切换完成后，哨兵就会向 `+switch-master` 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了**。
         
         通过发布者/订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。
      
      ## 其他
      
      1. 这玩意不能回滚！！！
      
      2. - 第一步是，客户端获取当前时间（t1）。
         - 第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作：
           - 加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。
           - 如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。
         - 第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。
      
      3. 大key的持久化影响
         
         当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。
         
         AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 `fork()` 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：
         
         - 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；
         - 创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。
         
         大 key 除了会影响持久化之外，还会有以下的影响。
         
         - 客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
         
         - 引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
         
         - 阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
         
         - 内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。
         
         如何避免大 Key 呢？
         
         最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。
         
         完！


